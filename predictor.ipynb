{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd258298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c998505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/vedant/Downloads/archive (1)\\data/food-101-tiny/valid',\n",
    "    batch_size=32,\n",
    "    image_size=(180, 180)\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befa16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calorie_mapping = {\n",
    "    'apple_pie': 237,\n",
    "    'bibimbap': 560,\n",
    "    'cannoli': 230,\n",
    "    'edamame': 122,\n",
    "    'falafel': 333,\n",
    "    'french_toast': 229,\n",
    "    'ice_cream': 273,\n",
    "    'ramen': 436,\n",
    "    'sushi': 306,\n",
    "    'tiramisu': 492\n",
    "}\n",
    "calorie_values = np.array([calorie_mapping[name] for name in class_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0124c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined calorie_mapping and class_names\n",
    "\n",
    "# Convert calorie_mapping to a TensorFlow lookup table\n",
    "calorie_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(list(calorie_mapping.keys())),\n",
    "        values=tf.constant(list(calorie_mapping.values()), dtype=tf.float32)\n",
    "    ),\n",
    "    default_value=tf.constant(0.0)\n",
    ")\n",
    "\n",
    "def preprocess(images, labels):\n",
    "    images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "    \n",
    "    # Convert class names to calorie values\n",
    "    calorie_values = calorie_table.lookup(tf.gather(class_names, labels))\n",
    "    \n",
    "    return images, calorie_values\n",
    "\n",
    "# Apply the preprocessing to your dataset\n",
    "preprocessed_dataset = dataset.map(preprocess)\n",
    "\n",
    "# Split the dataset\n",
    "train_ds = preprocessed_dataset.take(int(len(dataset) * 0.8))\n",
    "val_ds = preprocessed_dataset.skip(int(len(dataset) * 0.8))\n",
    "\n",
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa90ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/vedant/Downloads/archive (1)\\data/food-101-tiny/valid',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)  # Changed from (180, 180)\n",
    ")\n",
    "\n",
    "# Then update your model input shape\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(180, 180, 3),\n",
    "    include_top=False,\n",
    "    weights=None  # Initialize without pre-trained weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b44b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(180, 180, 3),\n",
    "    include_top=False,\n",
    "    weights=None  # Initialize without pre-trained weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd74f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - loss: 117214.7812 - mae: 315.3896 - val_loss: 123316.1406 - val_mae: 323.2070\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4s/step - loss: 89826.8906 - mae: 271.3820 - val_loss: 122154.6719 - val_mae: 321.4052\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4s/step - loss: 50477.2617 - mae: 193.6122 - val_loss: 118789.4688 - val_mae: 316.1267\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4s/step - loss: 23705.7598 - mae: 125.4270 - val_loss: 107232.4766 - val_mae: 297.2863\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - loss: 11638.7334 - mae: 83.2422 - val_loss: 94927.9922 - val_mae: 275.8163\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - loss: 11874.6172 - mae: 91.5394 - val_loss: 84529.9062 - val_mae: 256.2744\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - loss: 8073.4272 - mae: 68.0691 - val_loss: 77805.1562 - val_mae: 242.7999\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - loss: 5945.9092 - mae: 56.6370 - val_loss: 78529.9453 - val_mae: 244.2879\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - loss: 4796.1260 - mae: 51.8813 - val_loss: 77109.3047 - val_mae: 241.3627\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - loss: 2852.9822 - mae: 42.2155 - val_loss: 78830.2656 - val_mae: 244.9018\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer for calorie prediction\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9cf2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5598ecf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/vedant/Downloads/archive (1)\\\\data/food-101-tiny/valid\\\\apple_pie'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Create batch axis\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mmobilenet_v2\u001b[38;5;241m.\u001b[39mpreprocess_input(img_array)\n\u001b[1;32m---> 21\u001b[0m test_data \u001b[38;5;241m=\u001b[39m [load_and_preprocess_image(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m test_images]\n\u001b[0;32m     22\u001b[0m test_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(test_data)\n",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Create batch axis\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mmobilenet_v2\u001b[38;5;241m.\u001b[39mpreprocess_input(img_array)\n\u001b[1;32m---> 21\u001b[0m test_data \u001b[38;5;241m=\u001b[39m [load_and_preprocess_image(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m test_images]\n\u001b[0;32m     22\u001b[0m test_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(test_data)\n",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m, in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_image\u001b[39m(img_path):\n\u001b[1;32m---> 16\u001b[0m     img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n\u001b[0;32m     17\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[0;32m     18\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Create batch axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/vedant/Downloads/archive (1)\\\\data/food-101-tiny/valid\\\\apple_pie'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "test_dir = 'C:/Users/vedant/Downloads/archive (1)\\data/food-101-tiny/valid'\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for food_item in os.listdir(test_dir):\n",
    "    if food_item in calorie_mapping:\n",
    "        img_path = os.path.join(test_dir, food_item)\n",
    "        test_images.append(img_path)\n",
    "        test_labels.append(food_item)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "\n",
    "test_data = [load_and_preprocess_image(img_path) for img_path in test_images]\n",
    "test_data = np.vstack(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7807a282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f11f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a5166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
